From: Gordon Malm <gengor@gentoo.org>

PaX: Add changes from pax-2.6.28.7-test20 which are not
yet integrated into main grsecurity-2.6.28.x patch.

--- a/arch/x86/boot/compressed/head_32.S
+++ b/arch/x86/boot/compressed/head_32.S
@@ -80,8 +80,8 @@
 	/* Add 8 bytes for every 32K input block */
 	shrl $12, %eax
 	addl %eax, %ebx
-	/* Add 32K + 18 bytes of extra slack */
-	addl $(32768 + 18), %ebx
+	/* Add 64K of extra slack */
+	addl $65536, %ebx
 	/* Align on a 4K boundary */
 	addl $4095, %ebx
 	andl $~4095, %ebx
--- a/arch/x86/mm/pat.c
+++ b/arch/x86/mm/pat.c
@@ -491,6 +491,13 @@
 	return vma_prot;
 }
 
+#ifndef CONFIG_STRICT_DEVMEM
+/* This check is done in drivers/char/mem.c in case of STRICT_DEVMEM*/
+static inline int range_is_allowed(unsigned long pfn, unsigned long size)
+{
+	return 1;
+}
+#else
 /* This check is needed to avoid cache aliasing when PAT is enabled */
 static inline int range_is_allowed(unsigned long pfn, unsigned long size)
 {
@@ -513,6 +520,7 @@
 	}
 	return 1;
 }
+#endif /* CONFIG_STRICT_DEVMEM */
 
 int phys_mem_access_prot_allowed(struct file *file, unsigned long pfn,
 				unsigned long size, pgprot_t *vma_prot)
--- a/drivers/lguest/core.c
+++ b/drivers/lguest/core.c
@@ -80,9 +80,17 @@ static __init int map_switcher(void)
 	 * (SWITCHER_ADDR).  We might not get it in theory, but in practice
 	 * it's worked so far.  The end address needs +1 because __get_vm_area
 	 * allocates an extra guard page, so we need space for that. */
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	switcher_vma = __get_vm_area(TOTAL_SWITCHER_PAGES * PAGE_SIZE,
+				     VM_ALLOC | VM_KERNEXEC, SWITCHER_ADDR, SWITCHER_ADDR
+				     + (TOTAL_SWITCHER_PAGES+1) * PAGE_SIZE);
+#else
 	switcher_vma = __get_vm_area(TOTAL_SWITCHER_PAGES * PAGE_SIZE,
 				     VM_ALLOC, SWITCHER_ADDR, SWITCHER_ADDR
 				     + (TOTAL_SWITCHER_PAGES+1) * PAGE_SIZE);
+#endif
+
 	if (!switcher_vma) {
 		err = -ENOMEM;
 		printk("lguest: could not map switcher pages high\n");
